
Managing OpenShift Alerts
Objectives
After completing this section, you should be able to send alerts to external locations.

Describing Alertmanager Default Receivers
By default, alerts are not sent to external locations. The OpenShift web console displays alerts at Monitoring â†’ Alerting; alerts are accessible from the Alertmanager API also.

[user@demo ~]$ ALERTMANAGER="$(oc get route/alertmanager-main \
>   -n openshift-monitoring -o jsonpath='{.spec.host}')"

[user@demo ~]$ curl -s -k -H "Authorization: Bearer $(oc sa get-token \
>   prometheus-k8s -n openshift-monitoring)" \
>   https://${ALERTMANAGER}/api/v1/alerts | jq
Configure Alertmanager to send alerts to external locations such as email, PagerDuty, and HipChat so that you are promptly notified about cluster problems.

Alertmanager sends alerts to the locations configured in the alertmanager-main secret in the openshift-monitoring namespace.

This is the default configuration of the alertmanager-main secret. The double quotes can be removed to improve readability.

"global":
  "resolve_timeout": "5m" 1
"receivers":
- "name": "null"
"route":
  "group_by":
  - "namespace"
  "group_interval": "5m" 2
  "group_wait": "30s" 3
  "receiver": "null" 4
  "repeat_interval": "12h" 5
  "routes": 6
  - "match":
      "alertname": "Watchdog" 7
    "receiver": "null"
1

Value used by Alertmanager if the alert does not include a EndsAt field. After this time passes it can declare the alert as resolved if it has not been updated.

2

How long to wait before sending a notification about new alerts that are added to a group of alerts for which an initial notification has already been sent.

3

How long to wait to send an initial notification for a group of alerts. Allows for waiting for an inhibiting alert to arrive or for collecting more initial alerts for the same group.

4

This is the default receiver for notifications. A value of null indicates that it does nothing. All instances of null are typically changed to something else, such as default.

5

How long to wait before sending a notification again if it has already been sent successfully for an alert.

6

A route block defines a node in a routing tree and its children. Its optional configuration parameters are inherited from its parent node if not set.

7

Define a filter of type alertname.

Sending Alerts to PagerDuty
If your company already uses PagerDuty, then you will likely send alerts about your OpenShift cluster to PagerDuty. You can route alerts to cellphones, pagers, and email addresses also. The Prometheus Integration Guide on the PagerDuty website describes how to configure PagerDuty for Prometheus notifications. The following configuration sends critical alert messages to PagerDuty.

"global":
  "resolve_timeout": "5m"
"receivers":
- "name": "pagerduty-notification" 1
  "pagerduty_configs":
    "service_key": "e679d31da9b34aa4b8bb4f412186546d" 2
- "name": "default"
"route":
  "group_by":
  - "job"
  "group_interval": "5m"
  "group_wait": "30s"
  "receiver": "default"
  "repeat_interval": "12h"
  "routes":
  - "match":
      "alertname": "Watchdog"
    "receiver": "default"
  - "match":
      "severity": "critical" 3
    "receiver": "pagerduty-notification"
1

An arbitrary name that is used by an associated route.

2

The PagerDuty integration key for Prometheus. The service_key property corresponds to the PagerDuty Events API v1. The routing_key property is used for the PagerDuty Events API v2.

3

The matching criteria for the alert.

Multiple PagerDuty receivers can be configured so that different types of alerts are sent to the appropriate teams. Consult the References section for additional details.

Sending Alerts to Email
Alerts can be sent by email through an SMTP server. The following example sends critical alerts to the ocp-admins@example.com email alias.

"global":
  "resolve_timeout": "5m"
  "smtp_smarthost": "utility.lab.example.com:25" 1
  "smtp_from": "alerts@ocp4.example.com" 2
  "smtp_auth_username": "smtp_training" 3
  "smtp_auth_password": "Red_H4T@!" 4
  "smtp_require_tls": false 5
"receivers":
- "name": "email-notification" 6
  "email_configs": 7
    - "to": "ocp-admins@example.com" 8
- "name": "default"
"route":
  "group_by":
  - "job"
  "group_interval": "5m"
  "group_wait": "30s"
  "receiver": "default"
  "repeat_interval": "12h"
  "routes":
  - "match":
      "alertname": "Watchdog"
    "receiver": "default"
  - "match":
      "severity": "critical"
    "receiver": "email-notification" 9
1

The global SMTP host. This host is used if smarthost is not defined in the email_configs for a receiver.

2

The global email sender address. This address is used if from is not defined in the email_configs for a receiver.

3

The global SMTP user name for optional authentication. This user name is used if auth_username is not defined in the email_configs for a receiver.

4

The global SMTP password for optional authentication. This password is used if auth_password is not defined in the email_configs for a receiver.

5

A global setting specifying if TLS is required for SMTP. This setting can be overridden using require_tls in the email_configs for a receiver.

6

An arbitrary name for the receiver. A route specifies this receiver name for a match.

7

This setting indicates that the receiver will send alerts by email.

8

The to setting must be specified under email_conifgs and does not have an equivalent global SMTP setting.

9

The receiver to use if the match evaluates as true for the alert.

Applying a New Alertmanager Configuration
Apply a new Alertmanager configuration by updating the alertmanager-main secret in the openshift-monitoring namespace.

[user@demo ~]$ oc set data secret/alertmanager-main \
>   -n openshift-monitoring --from-file=/tmp/alertmanager.yaml
secret/alertmanager-main data updated
A successful update generates the log message: "Completed loading of configuration file" file=/etc/alertmanager/config/alertmanager.yaml Check for this message in the alertmanager container within the alertmanager-main-0 pod in the openshift-monitoring namespace. An incorrect configuration generates a failed log message.

[user@demo ~]$ oc logs -f -c alertmanager alertmanager-main-0 \
>   -n openshift-monitoring
...output omitted...
level=info ts=2020-05-15T18:53:09.052Z caller=coordinator.go:119 component=configuration msg="Loading configuration file" file=/etc/alertmanager/config/alertmanager.yaml
level=info ts=2020-05-15T18:53:09.052Z caller=coordinator.go:131 component=configuration msg="Completed loading of configuration file" file=/etc/alertmanager/config/alertmanager.yaml